---
title: "QANT 530 Homework #2"
author: "Phan Nguyen - 770034391 "
date: "07/21/2022"
output: 
  pdf_document:
    latex_engine: xelatex
fontsize: 11pt 
---

For this homework, we are going to do a multiple regression analysis on a practice dataset with 150 rows and five columns. 
This dataset represents stores of a company, where each row is a seperate stores.
For this exercise, the response variable is AverageMonthlyOrders. Below is a sample of the dataset. 

```{r include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.width=6, fig.height=6, fig.align="center")
par(mar=c(0,0,0,0))
library(tidyverse)
library(xlsx)
library(psych)
```
Region is categorical and assumably nominal. 
Number of employees, inventory value and average monthly orders are continuous.  
  
Table 1: Dataset example  
```{r  message=FALSE}

data <- read.xlsx("./datasets/Practice Dataset .xlsx", 1)
data <- data[,0:4]
head(data)
response <- data$AverageMonthlyOrders

```

### 1. Exploratory Analysis on the response variable

**Descriptive numerical summary table**  
Table 2: Descriptive Statistics table for AverageMonthlyOrders

```{r }
describe(response, ranges=TRUE, quant=c(.25,.75))
```

AverageMonthlyOrders has a logical range of values, from 214.03 to 455.06. 
Its median and mean are close, meaning its distrubtion is not skewed toward left or right.
The interquartile range is between 288.8 and 365.07, meaning 50% of the values are in between this range. 
Standard deviation is 49.6, meaning 95% of values are two standard deviations from the mean, between 226.25 and 424.65, according to empirical rules.
  
Skewness for AverageMonthlyOrders are quite close to 0, suggesting that the distribution for the variable is not quite skewed.
The measures of center also suggested the same. 
The excess kurtosis is around -0.4. Excess kurtosis is equal to normal kurtosis - 3.
In this case, the kurtosis shows that the distribution is close to a normal distribution.
AverageMonthlyOrders's distribution has heavier tails and lower bell, due to its kurtosis to be lower than 0.  
\  
\  
\  
\  
\  
  

**Descriptive chart summaries**    
```{r }
par(mar=c(4,4,0,0))
hist(response, main = "",xlab="Average Monthly Orders", breaks=10)
```
\begin {center} Figure 1: Histogram of AverageMonthlyOrders  \end{center}

This histogram shows the distribution for AverageMonthlyOrders. It does look like the distribution is bimodal, meaning there are two modes, thus two peaks in this histograms. 
The median and mean bin [300,350] doesn't have a high frequency, which means this distribution is not normal.
The right tail has lower frequency than the left tail.  

```{r }
par(mar=c(0,4,0,0))
boxplot(response)
```
\begin{center} Figure 2: Boxplot of AverageMonthlyOrders  \end{center}  
  
  
Visually, the boxplot of this variable looks normal. There are whiskers indicating the maximum and minimum values, corresponding to what we saw in the numerical descriptive statistcs.
The gray box represents the interquartile range, where the lower bound is the first quartile and the upper bound is the third quartile.
The black line in the middle indicates the median. We can see that the median is in the middle of this gray box, meaning it has approximately the same range to the first and third quartiles. 
We can't tell that this variable has a mode different than the median, which is interesting. 

### 2. Scatterplot analysis
```{r }
pairs(AverageMonthlyOrders~NumberOfEmployees + InventoryValue + factor(Region), lower.panel=NULL,data=data)
 
```
\begin{center}Figure 3: Scatterplot Matrix \end{center}  

Next, we create a scatterplot matrix between our response variable AverageMonthlyOrders and the explanatory variables. 
The scatterplot between AverageMonthlyOrders and Number of Employees shows a clear linear upward trend. It looks like more employees bring more average monthly orders. 
There are also an upward trend between regions and average monthly orders, which is very interesting. Regions are nominal, so if we give the regions a different numbers, they are not going to change their meaning in the dataset.
So it was interesting that coincidentally, they are sorted in a way that created a linear trend. However, since they are categorical, this doesn't tell us a lot about their correlation. 
There is no distinctive pattern between InventoryValue and AverageMonthlyOrders. 

Table 3: Correlation Matrix

```{r}
cor(data,method="pearson")
```


We can see that there are strong correlation - near 1 - between number of employees and average monthly orders. 
The correlation between regions and average monthly orders is high as well, however, since Region is nominal, it doesn't mean much, 
Week correlation between AverageMonthlyOrders and InventoryValue.  
It looks like the explanatory variables are not correlated, so there is no multicollinearity problem.


### 3. Multiple regression assumption check 
First, we fit the data into a model to check all assumptions. Response variable is AverageMonthlyOrders.

```{r}
model <- lm(AverageMonthlyOrders~NumberOfEmployees + InventoryValue + factor(Region), data=data)
res <- resid(model)
par(mfrow = c(2, 2))
plot(model)
```
\begin{center}Figure 4: Simple Regression Plots for models \end{center}  

We can check the assumptions for the multiple regression model using these plots. 
The residual plot on the left hand side, shows how the predicted versus observed values.
Ideally, the red line will stay horizontally at 0. In this case, the red line is approximately horizontal and at line 0. 
The points are scattered and don't follow any pattern. We can conclude that the **linearity and equal variances assumptions are met**. 
  
Independence of variance can be checked using the Scale-Location plot, on the bottom left hand. The red line supposed to be horizontally at zero for the assumption to be met. 
We can say that **the indpendence of variance assumption is met**.  
  
The normal Q-Q plots on the top right shows visually a straight line, meaning that **the normality assumption is met**.  
  
Earlier in the analysis, we agreed that there is no multicollinearity problem, meaning the independent variables are not correlated with other.  

### 4. Multiple Linear Regression model 
The assumptions are warranted for us to run a multiple regression model. 
Since Region is nominal, we will create dummy variable for it. 
  
Table 4: Regression statistics  
```{r}
summary(model)
```

The r-squared for the model is 0.914, suggesting that the independent variables explained 91.4% of variations in the response variable. 
The F-statistics is 253.2, and p-value is approximately 0, so the model is statistically significant. 
We wlll look at the varibles. Inventory Value and Region 2 and 3 are not statistically significant with alpha < 0.05.
We can't remove Region because two dummy varibles are not significant. However, we can remove InventoryValue and fit the model again. 

The new model without InventoryValue is

Table 5: Regression statistics, without InventoryValue  
```{r}
model <- lm(AverageMonthlyOrders~NumberOfEmployees + factor(Region), data=data)
summary(model)
```


The R-squared dropped a bit, but all variables are signficant, besides Region2 and Region3. The model as a whole is also significant.
F-test is 305.8, and its p-value is approximately 0, meaning there is a linear relationship between the explanatory and response variables.  
\  
\    
**Interpretation**   
    
Looking at this model, we can conclude that Number of Employees and Regions affect the number of avarage monthly orders.
For each increase of one employee in any regions, the average monthly orders increase averagely by 5.16.
Having stores in a certain regions also boost the number of orders. 
Having stores in region 4 increases AverageMonthlyOrders by 27.22 averagely, and 32.68 in region 5.
We can't conclude that store in region 2 and 3 will affect the number of monthly orders, since they are not statistically significant at alpha = 0.05 (their p-values are larger)


### 5. Residual Plots
```{r}
res <- resid(model)
plot(res)
```
\begin{center} Figure 5: Residual Plot \end{center}   
  
The residual plot indicates that there are no pattern in the error term. 
The points are scattered across the chart. It looks like our model is a good fit for the dataset. 




